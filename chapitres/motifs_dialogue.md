
---

## ğŸ§° Chapitre 3 â€” Les motifs du dialogue : construire un langage de conception avec les LLM

> Concevoir avec un LLM, câ€™est plus quâ€™Ã©crire des prompts. Câ€™est pratiquer un art du dialogue. Ce chapitre propose une bibliothÃ¨que de **motifs conversationnels** â€” des sÃ©quences typiques dâ€™interaction, issues du terrain, Ã  la fois rÃ©utilisables et adaptables.

---

### Pourquoi un langage de motifs ?

Dans le dÃ©veloppement logiciel, certaines situations reviennent sans cesse : formuler un besoin flou, explorer des options techniques, comprendre un code hÃ©ritÃ©, choisir une architecture. Avec un LLM, ces situations prennent une nouvelle forme â€” mais les **rÃ©currences dâ€™usage demeurent**.

> Un motif, câ€™est une **forme rÃ©currente dâ€™interaction efficace** dans un contexte donnÃ©. Il ne dicte pas quoi faire, mais propose un **cadre pour bien faire**.

---

## ğŸ”§ Structure dâ€™un motif

Chaque motif suit une structure claireâ€¯:

* **Nom** : une expression mÃ©morable
* **Contexte** : quand le motif sâ€™active
* **ProblÃ¨me** : ce qui empÃªche le progrÃ¨s
* **Solution** : la posture ou forme dâ€™interaction recommandÃ©e
* **ConsÃ©quences** : ce que cela permet
* **Exemple** : cas rÃ©el ou inspirÃ© du terrain
* **Variantes (facultatif)** : dÃ©clinaisons utiles
* **Outils associÃ©s (facultatif)** : IDE, plugin, canevasâ€¦

<div style="page-break-after: always;"></div>

---

## ğŸ“š BibliothÃ¨que de motifs

---

### ğŸ”· Motif 1 â€” *Question Socratique* : reformuler pour comprendre

**Contexte**
Un besoin est exprimÃ© de maniÃ¨re floue ou partielle, ou vous entrez dans un domaine que vous maÃ®trisez peu.

**ProblÃ¨me**
Un prompt vague produit une rÃ©ponse gÃ©nÃ©rique ou mal orientÃ©e.

**Solution**
Amorcer un **dialogue par questions progressives** pour clarifier lâ€™intention, comme un facilitateur ou un coach :

> Â« Quels types dâ€™erreurs souhaitez-vous capturer ? Â»
> Â« Quel canal de notification ? Quelle frÃ©quence ? Â»

**ConsÃ©quences**

* Clarifie les besoins, mÃªme pour lâ€™humain
* Enrichit le prompt au fil du dialogue
* Engage un raisonnement partagÃ©

**Exemple**
Demander Â« CrÃ©e un script dâ€™alerte Â» â†’ rÃ©ponse floue.
Poser 3 questions ciblÃ©es â†’ rÃ©ponse prÃ©cise, intÃ©grÃ©e au projet rÃ©el.

<p style="text-align: center;">
    <img src="../images/carte_mentale_motifs_dialogue.png" width="50%" />
</p>

<div style="page-break-after: always;"></div>

---

### ğŸ”· Motif 2 â€” *Exploration guidÃ©e* : dÃ©couper pour mieux avancer

**Contexte**
Vous devez explorer un domaine complexe ou inconnu.

**ProblÃ¨me**
Les rÃ©ponses sont trop gÃ©nÃ©ralistes. Trop de pistes, pas de structure.

**Solution**
Demander au LLM de proposer **une dÃ©composition en Ã©tapes**.

> Â« Quelles grandes Ã©tapes pour sÃ©curiser une API REST ? Â»
> Â« Propose-moi un plan dâ€™implÃ©mentation progressif. Â»

**ConsÃ©quences**

* RÃ©duction de la charge cognitive
* Planification par itÃ©ration
* Apprentissage ciblÃ© sur chaque sous-partie

**Exemple**
Migration monolithe â†’ microservices : demander les Ã©tapes, puis explorer chaque Ã©tape une Ã  une.

---

> **Une session de pairing augmentÃ©e**
>
> Lors dâ€™une sÃ©ance de co-dÃ©veloppement, deux dÃ©veloppeurs travaillent ensemble Ã  concevoir un module de traitement de factures. Lâ€™un dâ€™eux propose dâ€™interroger le LLM pour structurer le travail. Le prompt initial : *"Comment concevoir un module de traitement de factures dans un ERP ?"* produit une rÃ©ponse dense mais confuse.
>
> Lâ€™un des dÃ©veloppeurs reformule alors : *"Peux-tu me proposer une dÃ©composition en Ã©tapes pour construire ce module, du point de vue fonctionnel et technique ?"*
>
> Le LLM rÃ©pond :
>
> * Identifier les sources de donnÃ©es (factures fournisseurs, clients).
> * DÃ©finir les rÃ¨gles de validation.
> * ModÃ©liser les statuts de traitement.
> * IntÃ©grer les notifications.
> * PrÃ©voir lâ€™export comptable.
>
> Ã€ partir de cette rÃ©ponse, les deux dÃ©veloppeurs rÃ©organisent leur backlog, dÃ©finissent les premiÃ¨res user stories, et rÃ©digent ensemble les spÃ©cifications du MVP. Le LLM a non seulement servi de facilitateur technique, mais aussi de mÃ©diateur de comprÃ©hension mutuelle, rÃ©vÃ©lant des angles morts et clarifiant les prioritÃ©s. Lâ€™exploration guidÃ©e a permis de sortir du flou initial pour entrer dans lâ€™action concrÃ¨te.

<div style="page-break-after: always;"></div>

---

### ğŸ”· Motif 3 â€” *SpÃ©cification inversÃ©e* : remonter aux intentions Ã  partir du code

**Contexte**
Vous devez comprendre ou refactorer un code sans doc, sans contexte.

**ProblÃ¨me**
Le code prÃ©cÃ¨de la conception â€” impossible dâ€™en dÃ©duire les intentions.

**Solution**
Demander au LLM de **reconstituer la logique mÃ©tier, les hypothÃ¨ses, ou les user stories** Ã  partir du code.

> Â« Quelles rÃ¨gles mÃ©tier vois-tu dans ce code ? Â»
> Â« Quelle user story ce bloc implÃ©mente-t-il ? Â»

**ConsÃ©quences**

* Documentation rÃ©troactive
* DÃ©tection des biais ou trous logiques
* Meilleure maintenabilitÃ©

**Exemple**
Un script Python dâ€™analyse rÃ©seau est soumis au LLM. Il reconstruit les intentions et gÃ©nÃ¨re les cas de test.

**Variantes**

* 3.1 : *Reconstruction dâ€™User Story*
* 3.2 : *DÃ©duction des hypothÃ¨ses implicites*
* 3.3 : *Contrat dâ€™interface implicite*

---

> **Un LLM comme auditeur de code**
>
> Lors dâ€™un audit technique sur un systÃ¨me de facturation, une Ã©quipe se retrouve face Ã  un module PHP de plus de 800 lignes, Ã©crit il y a 8 ans, sans tests ni documentation. PlutÃ´t que de l'analyser ligne par ligne, lâ€™Ã©quipe dÃ©cide de le soumettre au LLM par blocs successifs.
>
> Ã€ chaque itÃ©ration, le prompt est : *"Quels traitements rÃ©alise ce bloc de code ? Quelle rÃ¨gle mÃ©tier cela semble-t-il implÃ©menter ?"*
>
> Le LLM identifie la dÃ©tection de doublons, la vÃ©rification de TVA, la gestion dâ€™arrondis, et les cas particuliers de facturation croisÃ©e. Ces Ã©lÃ©ments sont mis en parallÃ¨le avec les processus mÃ©tier dÃ©crits dans la documentation client, rÃ©vÃ©lant plusieurs Ã©carts non documentÃ©s.
>
> Cette approche de spÃ©cification inversÃ©e a permis de :
>
> * Documenter rÃ©troactivement un systÃ¨me critique,
> * RÃ©concilier la logique mÃ©tier et lâ€™implÃ©mentation rÃ©elle,
> * Planifier une refonte progressive sans repartir de zÃ©ro.

<div style="page-break-after: always;"></div>

---

### ğŸŒ€ Variantes du motif Â« SpÃ©cification InversÃ©e Â»

#### ğŸ“Œ Variante 3.1 : *Reconstruction dâ€™User Stories*

Au lieu de demander uniquement *ce que fait le code*, on pousse le LLM Ã  reformuler les intentions en *termes fonctionnels utilisateur*. Exemple de prompt :

> *Â« En supposant que ce code corresponde Ã  une fonctionnalitÃ© dâ€™un produit, quelle user story pourrait-on en dÃ©duire ? Â»*

**Usage** : utile dans des projets oÃ¹ le code a Ã©tÃ© produit avant la formalisation des besoins (souvent le cas dans des prototypes ou des phases de hackathon).

#### ğŸ“Œ Variante 3.2 : *DÃ©duction des HypothÃ¨ses*

Demandez au LLM :

> *Â« Quelles hypothÃ¨ses implicites ce code semble-t-il faire sur les donnÃ©es, les contextes dâ€™exÃ©cution ou les droits dâ€™accÃ¨s ? Â»*

**Usage** : prÃ©cieux pour dÃ©tecter des biais implicites, des prÃ©supposÃ©s sur les inputs, ou des angles morts en sÃ©curitÃ©.

#### ğŸ“Œ Variante 3.3 : *Contrat implicite*

Demandez :

> *Â« Peux-tu expliciter un contrat dâ€™interface pour cette fonction / ce module (types dâ€™entrÃ©es, sorties, erreurs gÃ©rÃ©es) ? Â»*

**Usage** : aide Ã  produire des *Design by Contract* Ã  posteriori, ou Ã  documenter des API sans doc initiale.

---

### ğŸ›  Mises en pratique concrÃ¨tes

#### âœ… Pratique 1 : GÃ©nÃ©rer les tests Ã  partir de lâ€™implÃ©mentation

Prompt-type :

> *Â« GÃ©nÃ¨re une suite de tests unitaires couvrant les cas normaux, limites et erreurs de cette fonction. Â»*

**RÃ©sultat** : Le LLM suggÃ¨re souvent des cas non couverts dans le code, rÃ©vÃ©lant des lacunes potentielles.

---

#### âœ… Pratique 2 : Ã‰crire la documentation avant refactorisation

Demande :

> *Â« RÃ©dige une documentation technique synthÃ©tique (fonction, paramÃ¨tres, exceptions, effets secondaires) Ã  partir de ce code. Â»*

**Usage** : crÃ©e un point dâ€™ancrage avant transformation, utile pour la relecture et le pair programming.

---

#### âœ… Pratique 3 : DÃ©tecter les effets de bord

Prompt :

> *Â« Est-ce que ce code a des effets secondaires non visibles immÃ©diatement (ex. : Ã©critures sur disque, accÃ¨s Ã  des variables globales, dÃ©pendances rÃ©seau) ? Â»*

**Usage** : audit de code legacy ou critique, base pour migration vers du code pur / testable.

---

### ğŸ”„ IntÃ©gration dans un workflow dâ€™Ã©quipe

Voici une **routine de revue de code assistÃ©e** utilisant ce motif :

1. ğŸ” *SÃ©lectionner une fonction critique Ã  revoir.*
2. ğŸ§  *Demander au LLM de reformuler son intention mÃ©tier.*
3. âœ… *GÃ©nÃ©rer les tests que cette fonction est supposÃ©e passer.*
4. ğŸ”„ *Comparer avec les tests existants.*
5. âœï¸ *Documenter ou enrichir Ã  la volÃ©e.*
6. ğŸ›  *DÃ©cider dâ€™un refactor ou non.*

> ğŸ”§ **Outil compagnon possible** : Un plugin ou script intÃ©grÃ© dans lâ€™IDE qui, Ã  la sÃ©lection dâ€™une fonction, envoie automatiquement un prompt de spÃ©cification inversÃ©e au LLM et affiche les hypothÃ¨ses mÃ©tier dans une fenÃªtre latÃ©rale.

---

### ğŸ§­ Posture recommandÃ©e

* Ne pas se contenter de *ce que le LLM dit*, mais comparer avec les hypothÃ¨ses de lâ€™Ã©quipe.
* Utiliser les rÃ©ponses comme **base de discussion**, notamment avec les parties prenantes non techniques.
* Croiser les approches : spÃ©cification inversÃ©e â†’ exploration guidÃ©e â†’ design dialoguÃ©.

<div style="page-break-after: always;"></div>

---

### ğŸ”· Motif 4 â€” *ModÃ¨le Miroir* : comparer pour Ã©clairer un choix

**Contexte**
Vous hÃ©sitez entre plusieurs implÃ©mentations possibles (par exemple, deux structures dâ€™API, deux algorithmes, deux stratÃ©gies dâ€™architecture), ou vous avez gÃ©nÃ©rÃ© plusieurs variantes avec le LLM et souhaitez les Ã©valuer de faÃ§on argumentÃ©e.

**ProblÃ¨me**
Lorsquâ€™on explore des options seul ou en Ã©quipe, il est facile de se focaliser sur une solution "plausible" sans bien comprendre les diffÃ©rences, les consÃ©quences ou les alternatives. Le LLM, sans guidance, tend Ã  gÃ©nÃ©rer une seule rÃ©ponse par dÃ©faut.

**Solution**
Exploitez le LLM comme un **miroir comparatif**. Demandez-lui explicitement de produire *plusieurs* versions dâ€™une mÃªme solution, puis de **les comparer lui-mÃªme selon des critÃ¨res dÃ©finis**. Câ€™est une mise en tension productive entre options, qui stimule lâ€™analyse critique.

> Â« Propose trois structures possibles pour ce composant. Compare-les sur lisibilitÃ©, performance et maintenabilitÃ©. Â»

**ConsÃ©quences**

* Analyse dialectique
* Explicitation des critÃ¨res de choix
* RÃ©duction du biais de confirmation

---

### ğŸ§ª Exemple concret

Lors dâ€™un projet de refonte de systÃ¨me de paiement, lâ€™Ã©quipe hÃ©site entre :

1. Une architecture orientÃ©e Ã©vÃ©nements avec Kafka.
2. Une architecture RESTful classique avec appels synchrones.

Le LLM est sollicitÃ© via ce prompt :

> *Â« Voici deux options dâ€™architecture. Peux-tu dÃ©tailler les avantages, risques et implications de chacune pour un systÃ¨me Ã  haute disponibilitÃ© devant traiter 100 transactions par seconde ? Â»*

Le modÃ¨le identifie que :

* Kafka apporte rÃ©silience et dÃ©couplage, mais complexifie la supervision.
* REST est plus simple Ã  auditer mais moins robuste en cas de pics de charge ou dâ€™erreurs rÃ©seau.

Cette analyse partagÃ©e permet Ã  lâ€™Ã©quipe de trancher plus sereinement, *en conscience*.

---

> ğŸ§­ **Le LLM comme miroir dâ€™Ã©quipe**
>
> Dans une rÃ©union de design technique, une Ã©quipe ne parvient pas Ã  se mettre dâ€™accord entre deux styles de validation de formulaire cÃ´tÃ© frontend : impÃ©ratif (en JS pur) ou dÃ©claratif (via une lib type Formik ou React Hook Form).
>
> Un dÃ©veloppeur propose de demander au LLM une comparaison structurÃ©e.
>
> Le prompt devient : *Â« Compare les styles impÃ©ratif et dÃ©claratif de validation de formulaire cÃ´tÃ© React. Donne des exemples de code et compare sur maintenabilitÃ©, UX et facilitÃ© de test. Â»*
>
> Le LLM rÃ©pond avec clartÃ©, exemples Ã  lâ€™appui, rÃ©vÃ©lant que le choix dÃ©pend du niveau de complexitÃ© mÃ©tier attendu et de lâ€™organisation du code. Cela permet Ã  lâ€™Ã©quipe de ne pas trancher "par opinion", mais sur des critÃ¨res explicites.
>
> Le modÃ¨le a servi ici de **facilitateur de clarification technique collective**, sans remplacer la dÃ©cision humaine.

---

### ğŸ”„ Variantes du motif Â« ModÃ¨le Miroir Â»

* **Miroir de styles** : comparer plusieurs styles de code pour une mÃªme logique (ex. fonctionnelle vs orientÃ©e objet).
* **Miroir de paradigmes** : comparer des approches (ex. polling vs event-driven).
* **Miroir de technologies** : comparer frameworks, langages, ou bibliothÃ¨ques en fonction dâ€™un usage ciblÃ©.

<div style="page-break-after: always;"></div>

---

### Motif 5 : *Clarification par contre-exemple* : Explorer les limites d'une proposition

**Contexte** : AprÃ¨s avoir reÃ§u une rÃ©ponse satisfaisante dâ€™un LLM, il arrive que des doutes subsistent : le code proposÃ© est-il robuste ? La solution envisagÃ©e tient-elle dans tous les cas ? Les limites implicites du raisonnement sont-elles comprises ?

**ProblÃ¨me** : Un prompt initialement bien formulÃ© peut conduire Ã  une rÃ©ponse correcte mais trop optimiste ou gÃ©nÃ©rique. Le LLM tend Ã  Â« deviner Â» une solution type, sans toujours prendre en compte les cas limites, les exceptions ou les erreurs de conception possibles. Cela donne lâ€™illusion de maÃ®trise, lÃ  oÃ¹ il faudrait de la rigueur.

**Solution** : Demander explicitement un contre-exemple ou une situation qui ferait Ã©chouer la solution proposÃ©e. Cette approche vise Ã  forcer la mise en lumiÃ¨re de zones grises, dâ€™angles morts ou de prÃ©supposÃ©s implicites. On peut formuler par exemple :

> Â« Quelle situation rend cette solution inefficace ? Â»
> Â« Et si les donnÃ©es sont mal formÃ©es ? Â»

Cette maniÃ¨re de questionner pousse le modÃ¨le (et le praticien) Ã  rÃ©flÃ©chir en creux, par la nÃ©gation ou lâ€™invalidation.

**ConsÃ©quences** :

* Renforce la robustesse de la solution en mettant Ã  lâ€™Ã©preuve ses fondements.
* Favorise une posture critique et antifragile dans la conception.
* Transforme le LLM en simulateur d'obstacles potentiels, utile pour la revue de code ou la documentation des limites dâ€™un systÃ¨me.

**Exemple** : Dans un atelier sur la gÃ©nÃ©ration dâ€™algorithmes de parcours de graphe, un Ã©tudiant a demandÃ© Ã  ChatGPT de lui fournir une version optimisÃ©e de Dijkstra en JavaScript. Le code gÃ©nÃ©rÃ© semblait parfaitement fonctionnel. En testant ensuite la robustesse du rÃ©sultat via la question : "Et si le graphe est orientÃ© avec des cycles nÃ©gatifs ?", le LLM a admis que lâ€™algorithme proposÃ© ne convenait pas, et a suggÃ©rÃ© de basculer sur Bellman-Ford avec un test d'intÃ©gritÃ© des poids. Cette interaction a permis non seulement dâ€™enseigner les limites dâ€™un algorithme, mais aussi dâ€™aiguiser lâ€™esprit critique face Ã  la "bonne rÃ©ponse".

---

> ğŸ“Œ **Posture rÃ©flexive : oser douter du bon Ã©lÃ¨ve**
>
> Lâ€™une des illusions les plus tenaces dans lâ€™usage des LLM est celle de la "rÃ©ponse parfaite" dÃ¨s la premiÃ¨re itÃ©ration. Un motif comme "Clarification par contre-exemple" invite Ã  adopter une posture scientifique : tester, falsifier, chercher ce qui ne va pas, mÃªme quand tout semble aller bien. Cela sâ€™apparente Ã  une relecture interne du raisonnement â€” une forme de revue de code dialoguÃ©e â€” oÃ¹ le dÃ©veloppeur devient enquÃªteur des failles possibles. Câ€™est aussi une maniÃ¨re de former les plus jeunes Ã  ne pas confondre autoritÃ© de lâ€™outil et vÃ©ritÃ© absolue.

<div style="page-break-after: always;"></div>

---

### ğŸ”· Motif 6 â€” *Prompt pilotÃ© par les tests* : dÃ©finir les attentes avant dâ€™Ã©crire

**Contexte**
Vous crÃ©ez un prompt pour un usage rÃ©current, mais les rÃ©ponses sont fluctuantes.

**ProblÃ¨me**
Sans attentes explicites, le LLM improvise. Les rÃ©sultats sont inconsistants.

**Solution**
Adoptez une dÃ©marche inspirÃ©e du Test-Driven Development : avant de rÃ©diger le prompt, Ã©crivez un ou plusieurs **tests dâ€™intention** qui dÃ©crivent ce que vous attendez du LLM. Ce peuvent Ãªtre :

* des exemples de sortie ;
* des critÃ¨res formels (format, style, structure) ;
* des contraintes de contexte ou de contenu.

Utilisez ensuite ces tests pour guider lâ€™Ã©criture du prompt. Faites-le Ã©voluer jusquâ€™Ã  ce quâ€™il satisfasse les attentes dÃ©finies.

**ConsÃ©quences**

* Vous gagnez en clartÃ© sur ce que vous attendez vraiment du modÃ¨le.
* Vos prompts deviennent plus robustes, plus rÃ©utilisables et plus faciles Ã  transmettre.
* Vous pouvez constituer une bibliothÃ¨que de prompts testÃ©s, versionnÃ©s et documentÃ©s.
* Le dialogue avec le LLM devient une activitÃ© dâ€™ingÃ©nierie Ã  part entiÃ¨re, structurÃ©e et maÃ®trisÃ©e.

**Exemple**
Une Ã©quipe travaillant sur un assistant de support client voulait gÃ©nÃ©rer automatiquement des rÃ©ponses types Ã  partir de tickets. Le prompt initial donnait des textes trop longs, trop formels et parfois hors sujet. En dÃ©finissant des tests dâ€™attente clairs â€” *"RÃ©ponse â‰¤ 3 phrases, ton empathique mais professionnel, ne jamais inclure dâ€™excuses juridiques"*, etc. â€”, lâ€™Ã©quipe a pu concevoir un prompt beaucoup plus prÃ©cis. Celui-ci a Ã©tÃ© intÃ©grÃ© dans leur base de connaissance, avec des versions pour diffÃ©rents registres de langue selon le client.

**Variations**

* **TDP visuel** : utilisez des "mock outputs" (sorties fictives attendues) comme rÃ©fÃ©rence.
* **TDP collaboratif** : faites dÃ©finir les attentes par plusieurs membres de lâ€™Ã©quipe (produit, technique, UX).
* **TDP dans le prompt** : incluez directement le test dans le prompt lui-mÃªme (ex. : *"Voici un exemple de rÃ©ponse attendue..."*).

<p style="text-align: center;">
    <img src="../images/tdp.png" width="50%" />
</p>

<div style="page-break-after: always;"></div>

---

## ğŸ¯ Motif 7 â€” *Reformulation Visuelle* : clarifier par la reprÃ©sentation

**Contexte**

Vous utilisez un LLM pour concevoir un systÃ¨me, une fonctionnalitÃ© ou un processus. Le modÃ¨le vous fournit une solution textuelle relativement structurÃ©e (architecture, algorithme, flux dâ€™information, dÃ©coupage de responsabilitÃ©s). Mais l'ambiguÃ¯tÃ© ou la complexitÃ© du texte rendent difficile une validation ou une mise en Å“uvre immÃ©diate. Vous soupÃ§onnez que des incohÃ©rences ou des zones dâ€™ombre subsistent.

**ProblÃ¨me**

Le langage naturel (ou pseudo-code) peut masquer des raccourcis logiques, des oublis dâ€™interfaces, des incompatibilitÃ©s ou des malentendus. Les solutions proposÃ©es par le LLM semblent correctes, mais manquent parfois de prÃ©cision dans la structure ou les interactions.

**Solution**

Transformez la rÃ©ponse du LLM en **schÃ©ma explicite**, puis reformulez ce schÃ©ma en **langage naturel structurÃ©**, que vous soumettez de nouveau au modÃ¨le. Ce processus permet de :

1. DÃ©tecter les zones ambiguÃ«s ou incohÃ©rentes,
2. Valider lâ€™adÃ©quation du modÃ¨le Ã  lâ€™intention initiale,
3. Enrichir ou complÃ©ter la proposition grÃ¢ce au dialogue.

Le schÃ©ma peut Ãªtre un diagramme de composants, de classes, de sÃ©quence, un cas dâ€™usage, une carte mentale, ou un simple tableau structurÃ©.

**Structure du dialogue**

```plaintext
1. Prompt initial â†’ RÃ©ponse LLM (textuelle)
2. SchÃ©ma du dÃ©veloppeur (hors modÃ¨le)
3. Reformulation du schÃ©ma en langage naturel
4. Prompt de validation ou dâ€™extension au LLM
5. RÃ©ponse LLM (corrections, suggestions, alternatives)
```

**ConsÃ©quences**

* Permet de faire Ã©merger des incohÃ©rences logiques plus tÃ´t.
* Clarifie les Ã©changes au sein de lâ€™Ã©quipe (support visuel commun).
* Favorise lâ€™appropriation de la solution par les humains.
* Renforce la capacitÃ© du LLM Ã  produire des propositions robustes (en lâ€™exposant Ã  des feedbacks explicites).
* DÃ©veloppe des compÃ©tences de modÃ©lisation chez les dÃ©veloppeurs.

**Exemple**

Dans un projet de refonte dâ€™un systÃ¨me de notifications multi-canaux, le LLM propose une architecture textuelle dÃ©crivant un service de gestion dâ€™alerte, un module de priorisation, une file dâ€™attente et un mÃ©canisme de diffusion. Un dÃ©veloppeur modÃ©lise cette proposition dans un diagramme de composants avec draw\.io, puis reformule :

> "Jâ€™ai interprÃ©tÃ© ta proposition ainsi : les alertes arrivent dans un gestionnaire, qui les classe, les stocke si besoin, et les transmet par webhook ou email. Redis sert de cache entre les modules. Ce schÃ©ma est-il cohÃ©rent ? Y a-t-il des points Ã  amÃ©liorer ?"

Le LLM identifie une faiblesse : lâ€™absence de gestion des Ã©checs dâ€™envoi. Il propose un mÃ©canisme de retry avec journalisation, enrichissant la solution.

**Variantes**

* Reformulation par **tableau Ã  double entrÃ©e** (utile en cas de rÃ´les et responsabilitÃ©s).
* Utilisation dâ€™**outils de modÃ©lisation UML**.
* Croisement avec des **cas dâ€™usage rÃ©digÃ©s** (user stories).
* Passage par **schÃ©ma manuscrit** + transcription.

**Anti-pattern**

Ne pas reformuler visuellement des propositions complexes peut conduire Ã  :

* une adhÃ©sion aveugle Ã  des solutions incomplÃ¨tes,
* une surconfiance dans les capacitÃ©s du LLM,
* des malentendus entre co-concepteurs humains.

<p style="text-align: center;">
    <img src="../images/reformulation_visuelle.png" width="50%" />
</p>

<div style="page-break-after: always;"></div>

---

### ğŸ”· Motif 8 â€” *Soin systÃ©mique* : investiguer les causes profondes dâ€™un problÃ¨me

**Contexte**
Un comportement inattendu, un problÃ¨me rÃ©current ou une tension dâ€™Ã©quipe Ã©merge sans cause Ã©vidente. La solution technique semble insuffisante ou incomplÃ¨te. Lâ€™Ã©quipe cherche Ã  comprendre "ce qui se joue vraiment" pour Ã©viter de traiter seulement les symptÃ´mes.

**ProblÃ¨me**
Les LLM sont souvent utilisÃ©s pour rÃ©soudre un problÃ¨me exprimÃ©, sans remettre en question la formulation du problÃ¨me lui-mÃªme. Cela peut conduire Ã  des solutions locales, sans impact durable, ou Ã  des rÃ©ponses rapides qui contournent les vraies causes. Lâ€™intention initiale est rarement interrogÃ©e en profondeur.

**Solution**
Utiliser le LLM comme **partenaire dâ€™investigation systÃ©mique**. Mobiliser un cadre comme le Neuf Pourquoi (Nine Whys) ou autre mÃ©thode dâ€™analyse causale, en formulant des prompts qui explorent les hypothÃ¨ses implicites, les causes possibles, les interactions systÃ©miques. Demander ensuite au modÃ¨le de proposer **des pistes dâ€™action ciblÃ©es** en lien avec les causes identifiÃ©es.

> ğŸ§­ **Les Neuf Pourquoi : creuser le sens pour mieux agir**
>
> InspirÃ© des **Liberating Structures**, le canevas des *Nine Whys* propose un rituel simple, mais puissant : poser neuf fois de suite la question **Â« Pourquoi est-ce important pour toi ? Â»** Ã  partir dâ€™un sujet donnÃ©.
>
> Loin dâ€™Ãªtre un interrogatoire, câ€™est un **chemin de clarification progressive**, oÃ¹ chaque rÃ©ponse devient la base de la question suivante. On ne cherche pas une cause unique, mais une **profondeur de sens** : ce qui motive vraiment lâ€™action, ce qui fonde les choix, ce qui compte profondÃ©ment.
>
> Dans le cadre du dÃ©veloppement logiciel, cet outil devient prÃ©cieux quand :
>
> * une dÃ©cision semble Ã©vidente mais suscite du flou ou de la rÃ©sistance,
> * un problÃ¨me technique rÃ©current cache des tensions humaines ou systÃ©miques,
> * une Ã©quipe veut aligner ses efforts sur ce qui a du sens.
>
> ğŸ‘‰ Le LLM peut ici jouer un rÃ´le de **facilitateur de questionnement** : en proposant des formulations de relance, en structurant les rÃ©ponses, ou en rÃ©vÃ©lant des contradictions implicites.
>
> > Exemples de prompts :
> >
> > *Â« Peux-tu mâ€™aider Ã  simuler une session de Nine Whys sur ce problÃ¨me : \[dÃ©crire la situation] ? Â»*
> > *Â« Ã€ chaque rÃ©ponse, propose une reformulation de "Pourquoi est-ce important ?" en changeant lÃ©gÃ¨rement lâ€™angle (valeurs, impact, Ã©motion, systÃ¨meâ€¦). Â»*
>
> En sollicitant un LLM avec ce cadre, on transforme une simple sÃ©ance dâ€™analyse en un **exercice de luciditÃ© collective**, capable de reconnecter la technique au sens.

**Prompt-type**

> Â« Voici un problÃ¨me rÃ©current dans notre Ã©quipe : \[dÃ©crire la situation]. Peux-tu mâ€™aider Ã  explorer les raisons profondes en utilisant la mÃ©thode des 5 ou 9 Pourquoi ? Â»
>
> Â« Pour chaque cause possible, quelles actions concrÃ¨tes pourrions-nous envisager ? Â»
>
> Â« Quelles causes sont techniques, relationnelles, organisationnelles ? Â»

**ConsÃ©quences**

* Favorise une comprÃ©hension plus fine des tensions et blocages.
* Permet dâ€™identifier des leviers dâ€™action non Ã©vidents.
* Soutient une posture rÃ©flexive, systÃ©mique, non rÃ©active.
* Offre un espace de dÃ©libÃ©ration partagÃ©e avec lâ€™IA comme catalyseur de recul.

**Exemple**
Une Ã©quipe constate une perte de motivation chez les dÃ©veloppeurs autour dâ€™un module complexe. Le LLM est dâ€™abord interrogÃ© sur comment "remotiver" â€” mais les rÃ©ponses sont superficielles. Le Scrum Master reformule avec :

> *Â« Pourquoi cette dÃ©motivation selon toi ? Peux-tu explorer plusieurs causes possibles en tâ€™appuyant sur les interactions humaines, les choix dâ€™architecture, le rythme de livraison ? Â»*

Le modÃ¨le identifie alors :

* un manque de clartÃ© dans les critÃ¨res de qualitÃ©,
* une dette technique anxiogÃ¨ne,
* une absence de cÃ©lÃ©bration des petits succÃ¨s.

Ã€ partir de lÃ , lâ€™Ã©quipe dÃ©finit plusieurs actions ciblÃ©es : des temps dâ€™alignement sur les critÃ¨res, des rituels de reconnaissance, un refactoring progressif. La cause systÃ©mique devient alors un levier dâ€™action partagÃ©.

**Variantes**

* **8.1 â€” Arbre des causes** : demander au LLM de gÃ©nÃ©rer un arbre logique des causes et sous-causes.
* **8.2 â€” Croisement de points de vue** : demander au modÃ¨le de formuler les causes vues par diffÃ©rents rÃ´les (PO, dev, ops, clientâ€¦).
* **8.3 â€” HypothÃ¨ses multiples** : inciter le modÃ¨le Ã  produire des hypothÃ¨ses contradictoires pour enrichir la rÃ©flexion.

---

## ğŸ§­ En rÃ©sumÃ© : la carte des motifs

| Motif                       | UtilitÃ© principale                     |
|-----------------------------|----------------------------------------|
| **Question socratique**     | Clarification, cadrage                 |
| **Exploration guidÃ©e**      | DÃ©composition, apprentissage           |
| **SpÃ©cification inversÃ©e**  | ComprÃ©hension, documentation           |
| **ModÃ¨le miroir**           | Choix argumentÃ©, design                |
| **Contre-exemple**          | Robustesse, critique                   |
| **Prompt pilotÃ© par les tests** | Prompt stable et reproductible         |
| **Reformulation visuelle**  | Langage commun, validation collective  |
| **Soin systÃ©mique**         | Analyse causale, investigation en profondeur |

---

> Chaque motif est une brique. Ensemble, ils forment un langage.
> Ce langage nâ€™est pas figÃ© â€” il est fait pour Ã©voluer avec vous.

---