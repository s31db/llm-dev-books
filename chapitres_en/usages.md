
---
<a id="usages"></a>
## ðŸŽ“ Chapter 11 â€” Using AI in Learning

### AI as a Tutor and Learning Partner

One of the most immediate uses of LLMs is **guided self-learning**.
A developer can query the model as a mentor available anytime â€” to ask for an explanation, an analogy, a code example, or a reformulation.

> **Examples:**
> â€“ *â€œCan you explain JavaScript closures to me as if I were 12?â€*
> â€“ *â€œShow me three versions of this function, from simplest to most optimized.â€*

This lets people learn at their own pace, quickly close knowledge gaps, and consolidate their understanding.
The LLM becomes a **permanent learning companion**, customizable and non-judgmental.

Many teams already encourage this as a natural reflex: donâ€™t stay blocked â€” â€œask the AIâ€ before interrupting a colleague â€” or, conversely, use it to prepare for a more focused discussion.

---

### AI-Assisted Documentation

Documentation is often neglected or postponed. With AI, itâ€™s now possible to generate it **incrementally and in context**, drawing from:

* reading a source file,
* a commit or ticket history,
* a technical chat exchange,
* a recorded demo.

> **Examples:**
> â€“ Automatically generate docstrings from code.
> â€“ Provide a technical summary of a module or a ticket.
> â€“ Synthesize a Markdown document from a Slack or Notion thread.

This on-demand documentation reduces cognitive friction, enables more regular updates, and makes it easier to share with non-technical roles (POs, UX, business stakeholdersâ€¦).

---

<div class="pb-A4"></div>

### Prompts as Versioned Artifacts

One of the most innovative concepts in this new paradigm is the **prompt as a documentation artifact**.
A well-crafted prompt can become a *resource in its own right*, just like a unit test or a Jira ticket.

> **Example:**
> A prompt used to generate an automated test plan or a component template can be stored, versioned, reviewed, shared, and adapted for other projects.

This means:

* keeping a record of important prompts (in Git, a wiki, or a prompt database),
* attaching their context (need, goal, constraints),
* reviewing them collectively (like code reviews).

Tools are already emerging around this idea â€” *prompt repositories*, *prompt templates*, *prompt linters*, etc. â€” fostering a culture of **transparency and shared design thinking**, where many decisions used to remain implicit.

---

### Team Workshops, Learning Loops, and Augmented Coaching

AI can also enrich team dynamics by feeding **collective learning rituals**.
Here are some effective formats:

#### â€œPrompt Clinicâ€ Workshop

Each member brings a prompt theyâ€™ve used, and the team discusses:

* its clarity,
* its robustness,
* the results obtained,
* possible improvements.

This shares prompting practices and cultivates a reflective stance.

#### Augmented Learning Loop

A mini AI-guided learning loop, for example:

1. Formulate a vague need.
2. First AI response.
3. Human reformulation.
4. AI refinement.
5. Document the process.

The team extracts a formal lesson (new pattern, architecture decision, example to keep).

#### Augmented Coaching

Technical or agile coaches can rely on AI to:

* rephrase technical points during reviews,
* suggest resources tailored to junior profiles,
* model different strategies for solving the same problem.

This accelerates skill growth without overloading the human transmission effort.

---

> **Prompt Book: A New Kind of Deliverable**
> 
> More and more teams document their LLM practices in a *prompt book* or *dialog-design notebook*: a structured collection of tested, annotated prompts tailored to their business context.
> This becomes **collective capital**, invaluable for onboarding, project memory, and upskilling.
